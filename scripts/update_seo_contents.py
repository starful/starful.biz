import os
import json
import re
import time
import google.generativeai as genai
from dotenv import load_dotenv

# --- ì„¤ì • ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-flash-latest")

CONTENTS_DIR = "app/contents"
BACKUP_DIR = "app/contents_seo_backup" # ë§Œì•½ì„ ëŒ€ë¹„í•œ ë°±ì—…

# --- AI í”„ë¡¬í”„íŠ¸ ì •ì˜ ---
SEO_UPDATE_PROMPT = """
You are an SEO expert and Japanese career consultant. 
Based on the job title "{position_name}", please provide the following in Japanese:

1. Long-tail Title: Create a catchy, SEO-optimized title (within 50 chars) that includes keywords like "å¹´å" (Salary), "å°†æ¥æ€§" (Future), "æœªçµŒé¨“" (Inexperienced), or "ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—" (Roadmap).
2. Salary Table: Create a Markdown table for estimated annual salaries in Japan based on data from doda and OpenWork.
   Columns: [çµŒé¨“å¹´æ•°, å¹´åç¯„å›² (ä¸‡å††), ç‰¹å¾´]
   Rows: [ã‚¸ãƒ¥ãƒ‹ã‚¢ (0-3å¹´), ãƒŸãƒ‰ãƒ« (3-7å¹´), ã‚·ãƒ‹ã‚¢ (7å¹´ä»¥ä¸Š/ë¦¬ë“œ)]

Format:
---TITLE---
[Generated Long-tail Title]
---TABLE---
[Generated Markdown Table]
"""

def parse_markdown_json(raw_content):
    """ê¸°ì¡´ íŒŒì¼ì˜ JSON ë©”íƒ€ë°ì´í„°ì™€ ë³¸ë¬¸ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    match = re.match(r'---json\s*(\{.*?\})\s*---(.*)', raw_content, re.DOTALL)
    if match:
        return json.loads(match.group(1).strip()), match.group(2).strip()
    return None, raw_content

def update_file(filename):
    file_path = os.path.join(CONTENTS_DIR, filename)
    with open(file_path, 'r', encoding='utf-8') as f:
        raw_content = f.read()

    metadata, body = parse_markdown_json(raw_content)
    if not metadata:
        print(f"â© Skip (No JSON found): {filename}")
        return

    position_name = metadata.get('slug', filename.replace('.md', '')).replace('_', ' ')
    print(f"ğŸ”„ SEO Updating: {position_name}...")

    try:
        response = model.generate_content(
            SEO_UPDATE_PROMPT.format(position_name=position_name),
            generation_config=genai.types.GenerationConfig(temperature=0.2)
        )
        ai_output = response.text

        # AI ê²°ê³¼ì—ì„œ íƒ€ì´í‹€ê³¼ í‘œ ì¶”ì¶œ
        new_title = re.search(r'---TITLE---\n(.*?)\n', ai_output).group(1).strip()
        salary_table = re.search(r'---TABLE---\n(.*)', ai_output, re.DOTALL).group(1).strip()

        # 1. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ë¡±í…Œì¼ ì œëª© ë°˜ì˜)
        metadata['title'] = new_title
        
        # 2. ë³¸ë¬¸ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë³¸ë¬¸ì˜ ë§¨ ì• í˜¹ì€ ì ì ˆí•œ ìœ„ì¹˜ì— ì—°ë´‰ í‘œ ì‚½ì…)
        # ì´ë¯¸ í‘œê°€ ìˆëŠ”ì§€ ì²´í¬ (ì¤‘ë³µ ë°©ì§€)
        if "å¹´åç¯„å›²" not in body:
            salary_section = f"\n\n## ğŸ’° æ—¥æœ¬ã§ã®æ¨å®šå¹´åï¼ˆdodaãƒ»OpenWorkå‚ç…§ï¼‰\n\n{salary_table}\n\n"
            # 1ë²ˆ ì„¹ì…˜(### 1.) ë’¤ì— ì‚½ì…í•˜ê±°ë‚˜ ë§¨ ìœ„ì— ì‚½ì…
            body = salary_section + body

        # 3. íŒŒì¼ ì €ì¥
        new_content = f"---json\n{json.dumps(metadata, ensure_ascii=False, indent=2)}\n---\n{body}"
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        print(f"âœ… Updated: {filename} -> {new_title}")
        return True

    except Exception as e:
        print(f"âŒ Error updating {filename}: {e}")
        return False

def main():
    if not os.path.exists(BACKUP_DIR):
        os.makedirs(BACKUP_DIR)

    files = [f for f in os.listdir(CONTENTS_DIR) if f.endswith(".md")]
    print(f"ğŸš€ Found {len(files)} files to SEO optimize.")

    for filename in files:
        # ë°±ì—… ìƒì„±
        with open(os.path.join(CONTENTS_DIR, filename), 'r', encoding='utf-8') as src:
            with open(os.path.join(BACKUP_DIR, filename), 'w', encoding='utf-8') as dst:
                dst.write(src.read())
        
        success = update_file(filename)
        if success:
            time.sleep(3) # API í• ë‹¹ëŸ‰ ì¡°ì ˆ

if __name__ == "__main__":
    main()